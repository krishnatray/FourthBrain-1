{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNnTTMT9dnM4"
   },
   "source": [
    "# Today you are a Data Scientist at Tesla! \n",
    "## You have been assigned a new project to look at car sales from Quarters 1-2 in California for 2019 to make predictions as to which cars will be sold more than the others in Q3 and Q4, to ensure enough inventory to meet demands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQqh5DMaq9QW"
   },
   "source": [
    "### If running this notebook in Google Colab, run the following cell first to mount your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1627687605649,
     "user": {
      "displayName": "Spencer Kent",
      "photoUrl": "",
      "userId": "07841346171340846448"
     },
     "user_tz": 420
    },
    "id": "Mqah54vN8CVB",
    "outputId": "8633c489-6439-4a66-dafd-cba26bc7e88d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NliK7yTn8LMn"
   },
   "source": [
    "^^ This mounts your Google Drive at the location */content/drive* on the virtual machine running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-eh9IKUfTdQ"
   },
   "source": [
    "# Task 1: Load data and wrangle training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OI6NP0JBdnM5"
   },
   "source": [
    "### Import some modules we'll make use of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WdNx3CHEdnM5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dM4fGT-ldnM8"
   },
   "source": [
    "### Read in the CSV file containing the California sales data for Quarters 1 and 2\n",
    "\n",
    "Then examine the data's shape and first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-s13HIEBdtGd"
   },
   "outputs": [],
   "source": [
    "# my copy of the Tesla sales data is located in my drive at /Datasets/week_1/\n",
    "# df_sales = pd.read_csv('/content/drive/My Drive/FourthBrain/Wk1/sales_Q12_2019.csv')\n",
    "df_sales = pd.read_csv('sales_Q12_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HdP5mSNQePPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5837, 76)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_S60_1</th>\n",
       "      <th>main_S60_2</th>\n",
       "      <th>main_type_SP100D</th>\n",
       "      <th>main_type_S60D_1</th>\n",
       "      <th>main_type_S60D_2</th>\n",
       "      <th>main_type_S70</th>\n",
       "      <th>main_type_S70D</th>\n",
       "      <th>main_type_S75</th>\n",
       "      <th>main_type_S75D</th>\n",
       "      <th>main_type_S80</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_24</th>\n",
       "      <th>sales_25</th>\n",
       "      <th>sales_26</th>\n",
       "      <th>sales_27</th>\n",
       "      <th>sales_28</th>\n",
       "      <th>sales_29</th>\n",
       "      <th>sales_30</th>\n",
       "      <th>MSRP</th>\n",
       "      <th>dealer_state</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44610</td>\n",
       "      <td>California</td>\n",
       "      <td>2019-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41505</td>\n",
       "      <td>California</td>\n",
       "      <td>2019-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58890</td>\n",
       "      <td>California</td>\n",
       "      <td>2019-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51055</td>\n",
       "      <td>California</td>\n",
       "      <td>2019-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70830</td>\n",
       "      <td>California</td>\n",
       "      <td>2019-01-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   main_S60_1  main_S60_2  main_type_SP100D  main_type_S60D_1  \\\n",
       "0           0           0                 0                 0   \n",
       "1           0           0                 0                 0   \n",
       "2           0           0                 0                 0   \n",
       "3           0           0                 0                 0   \n",
       "4           0           0                 0                 0   \n",
       "\n",
       "   main_type_S60D_2  main_type_S70  main_type_S70D  main_type_S75  \\\n",
       "0                 0              1               0              0   \n",
       "1                 0              0               0              0   \n",
       "2                 0              0               0              0   \n",
       "3                 0              0               0              0   \n",
       "4                 0              0               0              0   \n",
       "\n",
       "   main_type_S75D  main_type_S80  ...  sales_24  sales_25  sales_26  sales_27  \\\n",
       "0               0              0  ...         0         0         0         0   \n",
       "1               0              0  ...         0         0         0         0   \n",
       "2               0              0  ...         0         0         0         0   \n",
       "3               0              0  ...         0         0         0         0   \n",
       "4               0              0  ...         0         0         0         0   \n",
       "\n",
       "   sales_28  sales_29  sales_30   MSRP  dealer_state        date  \n",
       "0         0         0         0  44610    California  2019-04-28  \n",
       "1         0         0         0  41505    California  2019-03-14  \n",
       "2         0         0         0  58890    California  2019-06-12  \n",
       "3         0         0         0  51055    California  2019-03-04  \n",
       "4         0         0         0  70830    California  2019-01-23  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_sales.shape)\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9zWKdbKgHQCj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['main_S60_1', 'main_S60_2', 'main_type_SP100D', 'main_type_S60D_1',\n",
      "       'main_type_S60D_2', 'main_type_S70', 'main_type_S70D', 'main_type_S75',\n",
      "       'main_type_S75D', 'main_type_S80', 'main_type_S80D', 'main_type_S85',\n",
      "       'main_type_S85P', 'main_type_P85D', 'main_type_S90', 'main_type_S90D',\n",
      "       'main_type_S100D', 'engine_A', 'engine_B', 'engine_C', 'engine_D',\n",
      "       'engine_E', 'engine_F', 'engine_G', 'engine_H', 'engine_I', 'engine_J',\n",
      "       'engine_K', 'engine_L', 'engine_M', 'engine_N', 'engine_O', 'engine_P',\n",
      "       'engine_Q', 'engine_R', 'engine_S', 'engine_T', 'engine_U', 'engine_V',\n",
      "       'engine_W', 'engine_X', 'engine_Y', 'engine_Z', 'sales_1', 'sales_2',\n",
      "       'sales_3', 'sales_4', 'sales_5', 'sales_6', 'sales_7', 'sales_8',\n",
      "       'sales_9', 'sales_10', 'sales_11', 'sales_12', 'sales_13', 'sales_14',\n",
      "       'sales_15', 'sales_16', 'sales_17', 'sales_18', 'sales_19', 'sales_20',\n",
      "       'sales_21', 'sales_22', 'sales_23', 'sales_24', 'sales_25', 'sales_26',\n",
      "       'sales_27', 'sales_28', 'sales_29', 'sales_30', 'MSRP', 'dealer_state',\n",
      "       'date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_sales.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5837 entries, 0 to 5836\n",
      "Data columns (total 76 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   main_S60_1        5837 non-null   int64 \n",
      " 1   main_S60_2        5837 non-null   int64 \n",
      " 2   main_type_SP100D  5837 non-null   int64 \n",
      " 3   main_type_S60D_1  5837 non-null   int64 \n",
      " 4   main_type_S60D_2  5837 non-null   int64 \n",
      " 5   main_type_S70     5837 non-null   int64 \n",
      " 6   main_type_S70D    5837 non-null   int64 \n",
      " 7   main_type_S75     5837 non-null   int64 \n",
      " 8   main_type_S75D    5837 non-null   int64 \n",
      " 9   main_type_S80     5837 non-null   int64 \n",
      " 10  main_type_S80D    5837 non-null   int64 \n",
      " 11  main_type_S85     5837 non-null   int64 \n",
      " 12  main_type_S85P    5837 non-null   int64 \n",
      " 13  main_type_P85D    5837 non-null   int64 \n",
      " 14  main_type_S90     5837 non-null   int64 \n",
      " 15  main_type_S90D    5837 non-null   int64 \n",
      " 16  main_type_S100D   5837 non-null   int64 \n",
      " 17  engine_A          5837 non-null   int64 \n",
      " 18  engine_B          5837 non-null   int64 \n",
      " 19  engine_C          5837 non-null   int64 \n",
      " 20  engine_D          5837 non-null   int64 \n",
      " 21  engine_E          5837 non-null   int64 \n",
      " 22  engine_F          5837 non-null   int64 \n",
      " 23  engine_G          5837 non-null   int64 \n",
      " 24  engine_H          5837 non-null   int64 \n",
      " 25  engine_I          5837 non-null   int64 \n",
      " 26  engine_J          5837 non-null   int64 \n",
      " 27  engine_K          5837 non-null   int64 \n",
      " 28  engine_L          5837 non-null   int64 \n",
      " 29  engine_M          5837 non-null   int64 \n",
      " 30  engine_N          5837 non-null   int64 \n",
      " 31  engine_O          5837 non-null   int64 \n",
      " 32  engine_P          5837 non-null   int64 \n",
      " 33  engine_Q          5837 non-null   int64 \n",
      " 34  engine_R          5837 non-null   int64 \n",
      " 35  engine_S          5837 non-null   int64 \n",
      " 36  engine_T          5837 non-null   int64 \n",
      " 37  engine_U          5837 non-null   int64 \n",
      " 38  engine_V          5837 non-null   int64 \n",
      " 39  engine_W          5837 non-null   int64 \n",
      " 40  engine_X          5837 non-null   int64 \n",
      " 41  engine_Y          5837 non-null   int64 \n",
      " 42  engine_Z          5837 non-null   int64 \n",
      " 43  sales_1           5837 non-null   int64 \n",
      " 44  sales_2           5837 non-null   int64 \n",
      " 45  sales_3           5837 non-null   int64 \n",
      " 46  sales_4           5837 non-null   int64 \n",
      " 47  sales_5           5837 non-null   int64 \n",
      " 48  sales_6           5837 non-null   int64 \n",
      " 49  sales_7           5837 non-null   int64 \n",
      " 50  sales_8           5837 non-null   int64 \n",
      " 51  sales_9           5837 non-null   int64 \n",
      " 52  sales_10          5837 non-null   int64 \n",
      " 53  sales_11          5837 non-null   int64 \n",
      " 54  sales_12          5837 non-null   int64 \n",
      " 55  sales_13          5837 non-null   int64 \n",
      " 56  sales_14          5837 non-null   int64 \n",
      " 57  sales_15          5837 non-null   int64 \n",
      " 58  sales_16          5837 non-null   int64 \n",
      " 59  sales_17          5837 non-null   int64 \n",
      " 60  sales_18          5837 non-null   int64 \n",
      " 61  sales_19          5837 non-null   int64 \n",
      " 62  sales_20          5837 non-null   int64 \n",
      " 63  sales_21          5837 non-null   int64 \n",
      " 64  sales_22          5837 non-null   int64 \n",
      " 65  sales_23          5837 non-null   int64 \n",
      " 66  sales_24          5837 non-null   int64 \n",
      " 67  sales_25          5837 non-null   int64 \n",
      " 68  sales_26          5837 non-null   int64 \n",
      " 69  sales_27          5837 non-null   int64 \n",
      " 70  sales_28          5837 non-null   int64 \n",
      " 71  sales_29          5837 non-null   int64 \n",
      " 72  sales_30          5837 non-null   int64 \n",
      " 73  MSRP              5837 non-null   int64 \n",
      " 74  dealer_state      5837 non-null   object\n",
      " 75  date              5837 non-null   object\n",
      "dtypes: int64(74), object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    5837\n",
       "Name: dealer_state, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales['dealer_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_S60_1</th>\n",
       "      <th>main_S60_2</th>\n",
       "      <th>main_type_SP100D</th>\n",
       "      <th>main_type_S60D_1</th>\n",
       "      <th>main_type_S60D_2</th>\n",
       "      <th>main_type_S70</th>\n",
       "      <th>main_type_S70D</th>\n",
       "      <th>main_type_S75</th>\n",
       "      <th>main_type_S75D</th>\n",
       "      <th>main_type_S80</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_22</th>\n",
       "      <th>sales_23</th>\n",
       "      <th>sales_24</th>\n",
       "      <th>sales_25</th>\n",
       "      <th>sales_26</th>\n",
       "      <th>sales_27</th>\n",
       "      <th>sales_28</th>\n",
       "      <th>sales_29</th>\n",
       "      <th>sales_30</th>\n",
       "      <th>MSRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5837.0</td>\n",
       "      <td>5837.0</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>5837.0</td>\n",
       "      <td>5837.0</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0</td>\n",
       "      <td>5837.0000</td>\n",
       "      <td>5837.0</td>\n",
       "      <td>5837.0</td>\n",
       "      <td>5837.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56717.2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.3392</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3390</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12296.9406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47090.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56875.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91030.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       main_S60_1  main_S60_2  main_type_SP100D  main_type_S60D_1  \\\n",
       "count      5837.0      5837.0         5837.0000         5837.0000   \n",
       "mean          0.0         0.0            0.0021            0.0002   \n",
       "std           0.0         0.0            0.0453            0.0131   \n",
       "min           0.0         0.0            0.0000            0.0000   \n",
       "25%           0.0         0.0            0.0000            0.0000   \n",
       "50%           0.0         0.0            0.0000            0.0000   \n",
       "75%           0.0         0.0            0.0000            0.0000   \n",
       "max           0.0         0.0            1.0000            1.0000   \n",
       "\n",
       "       main_type_S60D_2  main_type_S70  main_type_S70D  main_type_S75  \\\n",
       "count         5837.0000      5837.0000       5837.0000         5837.0   \n",
       "mean             0.0009         0.1326          0.0036            0.0   \n",
       "std              0.0293         0.3392          0.0599            0.0   \n",
       "min              0.0000         0.0000          0.0000            0.0   \n",
       "25%              0.0000         0.0000          0.0000            0.0   \n",
       "50%              0.0000         0.0000          0.0000            0.0   \n",
       "75%              0.0000         0.0000          0.0000            0.0   \n",
       "max              1.0000         1.0000          1.0000            0.0   \n",
       "\n",
       "       main_type_S75D  main_type_S80  ...  sales_22  sales_23   sales_24  \\\n",
       "count       5837.0000      5837.0000  ...    5837.0    5837.0  5837.0000   \n",
       "mean           0.0002         0.0053  ...       0.0       0.0     0.1324   \n",
       "std            0.0131         0.0727  ...       0.0       0.0     0.3390   \n",
       "min            0.0000         0.0000  ...       0.0       0.0     0.0000   \n",
       "25%            0.0000         0.0000  ...       0.0       0.0     0.0000   \n",
       "50%            0.0000         0.0000  ...       0.0       0.0     0.0000   \n",
       "75%            0.0000         0.0000  ...       0.0       0.0     0.0000   \n",
       "max            1.0000         1.0000  ...       0.0       0.0     1.0000   \n",
       "\n",
       "        sales_25   sales_26  sales_27   sales_28  sales_29  sales_30  \\\n",
       "count  5837.0000  5837.0000    5837.0  5837.0000    5837.0    5837.0   \n",
       "mean      0.0541     0.0003       0.0     0.0065       0.0       0.0   \n",
       "std       0.2263     0.0185       0.0     0.0804       0.0       0.0   \n",
       "min       0.0000     0.0000       0.0     0.0000       0.0       0.0   \n",
       "25%       0.0000     0.0000       0.0     0.0000       0.0       0.0   \n",
       "50%       0.0000     0.0000       0.0     0.0000       0.0       0.0   \n",
       "75%       0.0000     0.0000       0.0     0.0000       0.0       0.0   \n",
       "max       1.0000     1.0000       0.0     1.0000       0.0       0.0   \n",
       "\n",
       "             MSRP  \n",
       "count   5837.0000  \n",
       "mean   56717.2895  \n",
       "std    12296.9406  \n",
       "min        0.0000  \n",
       "25%    47090.0000  \n",
       "50%    56875.0000  \n",
       "75%    65100.0000  \n",
       "max    91030.0000  \n",
       "\n",
       "[8 rows x 74 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"precision\", 4)\n",
    "df_sales.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF7w0UQndnM_"
   },
   "source": [
    "### Begin cleaning the data\n",
    "\n",
    "Eliminate the `'dealer_state'` and `'date'` columns. The former is useless to our model, since we already know that our dataset is restricted to California sales. While we could possibly extract useful information from the `'date'` column (for example, to determine whether more cars are sold on weekends than weekdays), we'll be focusing on car configurations in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-DThsrHdnNA"
   },
   "outputs": [],
   "source": [
    "df_sales = df_sales.drop(columns=['dealer_state','date'])\n",
    "print(df_sales.shape)\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in df_sales.columns if df_sales[col].std() == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqdkmnCodnNC"
   },
   "source": [
    "### Read in the CSV file containing the California sales data for Quarters 3 and 4\n",
    "\n",
    "The `'dealer_state'` and `'date'` columns have already been eliminated in this dataset, so you don't need to worry about them here. Examine the data's shape and first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJpTgHxAdnND"
   },
   "outputs": [],
   "source": [
    "# my copy of the Tesla sales data is located in my drive at /Datasets/week_1/\n",
    "df_pred = pd.read_csv('/content/drive/My Drive/Datasets/week_1/sales_Q34_2019.csv')\n",
    "print(np.shape(df_pred))\n",
    "print(df_pred.columns)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcmsU-T1dnNF"
   },
   "source": [
    "### Set up a regression problem that uses car IDs to predict proportion of # sold. \n",
    "\n",
    "You've probably noticed that 73 of the 74 columns in our Q12 and Q34 datasets\n",
    "are one-hot-encoded representations of the car's `'main_type'`, `'engine'`, and \n",
    "`'sales_version'` values. This could be viewed as a unique ID for each type of car. You've probably also noticed that the final column is \n",
    "the car's `'MSRP'`, or manufacturer's (Tesla's, in this case) suggested retail price. You could do several things with this data--we're asking you to fit a model of the **proportion of cars sold** based on the unique ID. You'll fit the model on Q12 data and test it on Q34 data. We won't use MSRP.\n",
    "\n",
    "Each row in the dataset represents the sale of a single car. So, we can count up\n",
    "the number of rows with a particular ID, and this gives us the number of times that specific type of car was sold in California during that time period. This number divided by the total number sold is the proportion of sales attributed to this particular type of car.\n",
    "\n",
    "<!-- \n",
    "\n",
    "\n",
    "Consolidate data by finding numbers of unique car combinations sold for training and test data sets\n",
    "\n",
    "\n",
    "\n",
    "However, each row represents the sale of a single car. If we define a unique car type by its combination of `'main_type'`, `'engine'`, and `'sales_version'` values, the number of rows displaying that combination corresponds to the number of times during that half of the year that that distinct type of car was sold in California. Therefore, we can make training and test datasets where each row now corresponds to a unique car type, and the target value is how many times that car type was sold in California during a given half of the year.\n",
    "\n",
    "## This task requires data wrangling!\n",
    "## Create functions that read the Q12 (df_sales) and Q34 (df_pred) data sets and create train_X, train_Y, test_X and test_Y, respectively. Use pandas and NumPy as needed. -->\n",
    "\n",
    "**Create a Python function called ``get_features_and_targets`` that takes in a quarterly sales dataframe and produces matrices $\\mathbf{X}$ and $\\mathbf{Y}$, where $\\mathbf{X}$ has in each row a unique car ID and the corresponding row of $\\mathbf{Y}$ has that specific car's proportion of total sales for the quarter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mo5c3VhBkB33"
   },
   "outputs": [],
   "source": [
    "def get_features_and_targets(df):\n",
    "  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toTX3W89fX2P"
   },
   "source": [
    "### Use your function to create $\\mathbf{X}$, $\\mathbf{Y}$, pairs for both the training data and the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rf6Vj0ujhJ77"
   },
   "outputs": [],
   "source": [
    "train_X, train_Y = get_features_and_targets(df_sales)\n",
    "test_X, test_Y = get_features_and_targets(df_pred)\n",
    "print(np.shape(train_X))\n",
    "print(f\"Number of unique cars in Q12 = {len(train_Y)}\")\n",
    "print(f\"Number of unique cars in Q34 = {len(test_Y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d7BSjsQdnNV"
   },
   "source": [
    "Okay, so let's note that the Q12 and Q34 datasets contain differing numbers of distinct cars. Clearly, some new models were introduced by Q3, but were any discontinued by the end of Q2? Let's find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7Z-Trs9o821"
   },
   "source": [
    "Print the number of cars that were sold in either Q12 or Q34, or both. In mathematical notation, if the set of cars sold in Q12 is $\\mathcal{A}$ and the set of cars sold in Q34 is $\\mathcal{B}$, we're asking for the size of the *union* of these two sets $|\\mathcal{A} \\cup \\mathcal{B}|$. The notation $|\\cdot|$ indicates measurement of the size of a set, the number of distinct items. (Mathematicians usually refer to it as the *cardinality*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOEhFSxin_te"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KgAprxHqcv2"
   },
   "source": [
    "A handy little fact from set theory is that $|\\mathcal{A} \\cup \\mathcal{B}| = |\\mathcal{A}| + |\\mathcal{B}| - |\\mathcal{A} \\cap \\mathcal{B}|$, where $\\cap$ is the *intersection* of $\\mathcal{A}$ and $\\mathcal{B}$, things that are in **both** $\\mathcal{A}$ and $\\mathcal{B}$. Use this fact, and what you've computed above, to print the number of models that were sold in both Q12 and Q34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56A3357NswMG"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clPi1NVCunoy"
   },
   "source": [
    "How many cars that were sold in Q12 were discontinued by Q34?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1627687607185,
     "user": {
      "displayName": "Spencer Kent",
      "photoUrl": "",
      "userId": "07841346171340846448"
     },
     "user_tz": 420
    },
    "id": "VmMdZNuzu5Z-",
    "outputId": "cf6cf2d7-1b6c-472a-c1d7-dfd5fa885816"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04zz5QOkvtij"
   },
   "source": [
    "How many cars were launched in Q34?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stRzG8THvyeA"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qn6SNBNdnNb"
   },
   "source": [
    "# Task 2: Visualize the training and test targets any way you see fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzsF0PfoyoyS"
   },
   "source": [
    "This is super open-ended and we're not expecting a particular visualization, just show us what comes comes to your mind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFVGTPYV2jrF"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9g-2fwgydnNh"
   },
   "source": [
    "# Task 3: Fit a linear model with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oriL0PcVOlw-"
   },
   "source": [
    "Set hyperparameters for learning rate and maximum number of iterations through the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKIv3936OfVk"
   },
   "outputs": [],
   "source": [
    "# these are good starting values, you can play around with them though\n",
    "s_learning_rate = 0.001\n",
    "s_max_iteration = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx-wS125dnNk"
   },
   "source": [
    "### Hypothesis Function\n",
    "\n",
    "Define your hypothesis function $h(\\cdot)$ (which you use to make predictions $\\hat{\\mathbf{Y}}$ as the matrix product of your feature data $\\mathbf{X}$ and parameters $\\boldsymbol{\\theta}$. $\\boldsymbol{\\theta}$, which you'll initialize in the training loop (below) is a column vector, one for every feature in the training data, plus one for bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SI8oTUQsdnNk"
   },
   "outputs": [],
   "source": [
    "# Define your hypothesis function according to the instructions above\n",
    "def h(theta, X):\n",
    "  ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LW5F5uhdnNm"
   },
   "source": [
    "Define your loss function as **half** the MSE (mean squared error) between your actual and predicted $\\mathbf{Y}$ values. \n",
    "\n",
    "Recall that the predicted $\\mathbf{Y}$ values, $\\hat{\\mathbf{Y}}$, are a function of $\\boldsymbol{\\theta}$ and $\\mathbf{X}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzRpZec4dnNm"
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def loss (theta, X, Y) :\n",
    "  ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCLgRXivdnNp"
   },
   "source": [
    "### Gradient of Hypothesis Function\n",
    "\n",
    "One can verify through straightforward (if somewhat tedious) multivariable calculus that the gradient of the loss function $J$ with respect to the parameters $\\theta$ is \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial \\boldsymbol{\\theta}} = - \\frac{1}{m} X^T \\cdot (Y - \\hat{Y})$$\n",
    "\n",
    "Where $m$ is the number of data samples, the number of rows in $\\mathbf{X}$ and $\\mathbf{Y}$.\n",
    "\n",
    "Note that the $\\mathbf{X}$ here is the one that has been augmented with a bias column. \n",
    "\n",
    "Set up a function ``gradient`` to compute this gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zYnvBa1dnNp"
   },
   "outputs": [],
   "source": [
    "def gradient (theta, X, Y) :\n",
    "  ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fo-NxmSLdnNr"
   },
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Complete the function ``stochastic_gradient_descent`` below, to train your linear regression model with gradient descent, i.e. calculate $\\frac{\\partial J}{\\partial \\theta}$ and update $\\theta$. Recall that the general gradient descent update formula is $\\theta := \\theta - \\alpha \\frac{\\partial J}{\\partial \\theta}$, with $\\alpha$ the stepsize. We've provided the skeleton of a stochastic gradient descent function, but you're welcome to experiment with batch and/or minibatch gradient descent. Also recall that the aforementioned gradient descent methods differ in how frequently they calculate $\\frac{\\partial J}{\\partial \\theta}$ and update $\\theta$. Notice in the first step we initialize $\\boldsymbol{\\theta}$ to all zeros and we temporarily prepend a column of $1$'s to the features, which corresponds to the bias parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6hbmDgkdnNs"
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, Y, learning_rate, max_iteration, print_interval):\n",
    "  theta = np.zeros((X.shape[1]+1, 1))\n",
    "  X_with_ones = np.hstack([np.ones([X.shape[0], 1]), X])  # prepend a column of 1s. This is just to make the math more compact, your original data is still X[:, 1:]\n",
    "  # Initialize the cost as an array of zeros, one for each iteration through the dataset\n",
    "  cost = np.zeros(max_iteration)\n",
    "  # Loop over the dataset\n",
    "  for i in range(max_iteration):\n",
    "    # Loop over each row in the dataset\n",
    "    for j in range(X.shape[0]):\n",
    "      # Compute the gradient from the current row in X and the associated Y value\n",
    "      # Make sure that both X and Y are represented as 2D row vectors\n",
    "      ## YOUR CODE HERE\n",
    "      # Update theta\n",
    "      ## YOUR CODE HERE\n",
    "    # Update the cost array for the current iteration\n",
    "    cost[i] = loss(theta, X_with_ones, Y)\n",
    "    if i % print_interval == 0 :\n",
    "      print('iteration : ', i, ' loss : ', loss(theta, X_with_ones, Y)) \n",
    "  return theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O084UJ8UdnNt"
   },
   "outputs": [],
   "source": [
    "s_theta, s_cost = stochastic_gradient_descent(train_X, train_Y, s_learning_rate, s_max_iteration, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoRR-pP8P2C2"
   },
   "outputs": [],
   "source": [
    "plt.stem(np.squeeze(s_theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6D2kqejdnNv"
   },
   "source": [
    "### Generate Predictions from Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-u3iTbNdnNw"
   },
   "outputs": [],
   "source": [
    "# remember that s_theta should be applied to features that have a prepended column of 1's\n",
    "pred_Y_from_GD = h(s_theta, np.hstack([np.ones([test_X.shape[0], 1]), test_X]))\n",
    "# Set any negative predictions to 0\n",
    "pred_Y_from_GD[pred_Y_from_GD<0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ImYOho6dnNy"
   },
   "source": [
    "### Visualize the predicted and actual test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3t83fxcr6dd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ljk24gJ4dnNy"
   },
   "outputs": [],
   "source": [
    "# compare predictions pred_Y_from_GD to test_Y. Report MSE and R^2 score\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNFkAA7gdnN0"
   },
   "source": [
    "# Task 4: Normal Equations\n",
    "\n",
    "Since our training dataset isn't very large, let's generate predictions using the normal equations: \n",
    "\n",
    "$$\\boldsymbol{\\theta} = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot Y$$ \n",
    "$$\\hat{Y} = X \\cdot \\boldsymbol{\\theta}$$\n",
    "\n",
    "and see how they compare to the predictions which we obtained from gradient descent. Remember we still have a bias term, so $\\boldsymbol{\\theta}$ is of size 74x1 (73 for the unique ID features, 1 for the bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ez7XC2qQdnN1"
   },
   "outputs": [],
   "source": [
    "def normal_equations_solution(X, Y):\n",
    "  X_with_ones = np.hstack([np.ones([train_X.shape[0], 1]), train_X])\n",
    "  ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAhtVznMZGtB"
   },
   "outputs": [],
   "source": [
    "# Compute the predicted Y values\n",
    "n_theta = normal_equations_solution(train_X, train_Y)\n",
    "pred_Y_from_N = np.matmul(np.hstack([np.ones([test_X.shape[0], 1]), test_X]), n_theta)\n",
    "\n",
    "# Set any negative predictions to 0\n",
    "pred_Y_from_N[np.where(pred_Y_from_N<0)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lu9NjgsJdnN3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot predictions compared to test_Y, and also print MSE and R^2 score\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3ofJxdUdnN6"
   },
   "source": [
    "### Regularized Normal Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1627687637973,
     "user": {
      "displayName": "Spencer Kent",
      "photoUrl": "",
      "userId": "07841346171340846448"
     },
     "user_tz": 420
    },
    "id": "VyIX4LaAdnN6",
    "outputId": "4011e415-a117-43ae-d5ff-57cc6f976a76"
   },
   "outputs": [],
   "source": [
    "print('Recall that our training features array train_X has')\n",
    "print(f'm = {train_X.shape[0]} rows and n = {train_X.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSvkrQ6EdnN8"
   },
   "source": [
    "`train_X` is thus wider than it is tall, which suggests that the regularized normal equations might perform better in generating label predictions. In this case, we modify the first of the normal equations given above to \n",
    "\n",
    "$$\\boldsymbol{\\theta} = (X^T \\cdot X + \\lambda m I)^{-1} \\cdot X^T \\cdot Y$$.\n",
    "\n",
    "Here, $\\lambda$ is the regularization parameter and $m$ is the number of rows in $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Mgd1zocdnN9"
   },
   "source": [
    "### Repeat the previous parts of Task IV, but this time incorporate regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFY5YO-IZ2e7"
   },
   "outputs": [],
   "source": [
    "def regularized_normal_equations_solution(X, Y, regularization_param):\n",
    "  X_with_ones = np.hstack([np.ones([train_X.shape[0], 1]), train_X])\n",
    "  ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIrbJkOydnN9"
   },
   "outputs": [],
   "source": [
    "test_these_lambdas = np.linspace(0.01, 10, 10)\n",
    "\n",
    "for i in test_these_lambdas:\n",
    "  theta_temp = regularized_normal_equations_solution(train_X, train_Y, i)\n",
    "  pred_Y_from_N_reg = np.matmul(np.hstack([np.ones([test_X.shape[0], 1]), test_X]), theta_temp)\n",
    "  pred_Y_from_N_reg[np.where(pred_Y_from_N_reg<0)]=0\n",
    "  print('For regularization parameter', i)\n",
    "  print(\"RMSE, R2 =\", MSE(test_Y, pred_Y_from_N_reg), r2_score(test_Y, pred_Y_from_N_reg))\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5uD0DVidnN_"
   },
   "source": [
    "# Task V: Non-linear Regression Models (GLM, DT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yk0Be7SQdnN_"
   },
   "source": [
    "### Generalized Linear Models\n",
    "\n",
    "`sm` (our alias for `statsmodels.api`) contains a `GLM` class. Use it to instantiate a model. The relevant parameters are training labels, training features, and `ffamily`, i.e. the family of distributions to which we assume our prediction errors belong. Some potentially good choices for `ffamily` include Gaussian, Gamma, and Logit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxUdD_LhdnN_"
   },
   "outputs": [],
   "source": [
    "# GLM \n",
    "import statsmodels.api as sm\n",
    "# Instantiate the GLM\n",
    "train_X_glm = sm.add_constant(train_X)\n",
    "glm_gamma = sm.GLM(train_Y, train_X_glm, family=sm.families.Gaussian())\n",
    "# Train the GLM\n",
    "glm_results = glm_gamma.fit()\n",
    "print(glm_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IAchWHodnOB"
   },
   "source": [
    "### Generate predictions from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLTsITX7dnOC"
   },
   "outputs": [],
   "source": [
    "# generate predictions, called pred_Y_from_GLM. (don't forget to add a constant column to test_X)\n",
    "## YOUR CODE HERE\n",
    "# Set any negative predictions to 0\n",
    "pred_Y_from_GLM[pred_Y_from_GLM<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgXIT-JpdnOE"
   },
   "outputs": [],
   "source": [
    "# Plot predictions compared to test_Y, and also print MSE and R^2 score\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vld0rNUcdnOG"
   },
   "source": [
    "### Random Forest Regression\n",
    "\n",
    "Use the `RandomForestRegressor` from `sklearn.ensemble` to generate predictions. The relevant parameters are the `max_depth` of the trees and the `random_state`, to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbxRUm3UdnOG"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate the random forest regression model\n",
    "regr = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "# Train the model\n",
    "## YOUR CODE HERE\n",
    "# Generate predictions from the test data\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSZX9t1MdnOK"
   },
   "outputs": [],
   "source": [
    "# Plot predictions compared to test_Y, and also print MSE and R^2 score\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxx1JrikdnON"
   },
   "source": [
    "\n",
    "## Populate the table below with the results of your experiments above. Which models performed best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44MPnft4dnON"
   },
   "source": [
    "## Results\n",
    "\n",
    "|Method      |RMSE             |R2               |\n",
    "|------------|-----------------|-----------------|\n",
    "| Gradient Descent | xx | xx|\n",
    "| Normal Equations | xx | xx |\n",
    "| Regularized Normal Equations | xx | xx |\n",
    "| Generalized Linear Model (GLM) | xx | xx |\n",
    "| Random Forests | xx | xx |\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "week1_V1.ipynb",
   "provenance": [
    {
     "file_id": "1A5aKkAXYKm5ju0TNG-1yU44-hnWEhh__",
     "timestamp": 1603344980309
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
